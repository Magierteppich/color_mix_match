{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Recognition Model using the cifar100 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source: https://stackabuse.com/image-recognition-in-python-with-tensorflow-and-keras/ --> Tutorial used\n",
    "# https://www.cs.toronto.edu/~kriz/cifar.html --> Dataset used\n",
    "# https://keras.io/examples/vision/image_classification_from_scratch/ --> Keras' own tutorial on image segmentation\n",
    "# https://machinelearningmastery.com/save-load-keras-deep-learning-models/ --> how to save the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://appliedmachinelearning.blog/2018/03/24/achieving-90-accuracy-in-object-recognition-task-on-cifar-10-dataset-with-keras-convolutional-neural-networks/\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.datasets import cifar100\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 100)               204900    \n",
      "=================================================================\n",
      "Total params: 493,700\n",
      "Trainable params: 492,804\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def lr_schedule(epoch):\n",
    "    lrate = 0.001\n",
    "    if epoch > 75:\n",
    "        lrate = 0.0005\n",
    "    if epoch > 100:\n",
    "        lrate = 0.0003\n",
    "    return lrate\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    " \n",
    "#z-score\n",
    "mean = np.mean(x_train,axis=(0,1,2,3))\n",
    "std = np.std(x_train,axis=(0,1,2,3))\n",
    "x_train = (x_train-mean)/(std+1e-7)\n",
    "x_test = (x_test-mean)/(std+1e-7)\n",
    " \n",
    "num_classes = 100\n",
    "y_train = to_categorical(y_train,num_classes)\n",
    "y_test = to_categorical(y_test,num_classes)\n",
    " \n",
    "weight_decay = 1e-4\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay), input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(32, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    " \n",
    "model.add(Conv2D(64, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.3))\n",
    " \n",
    "model.add(Conv2D(128, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(128, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    " \n",
    "model.add(Flatten())\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    " \n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    )\n",
    "datagen.fit(x_train)\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-17-8c129d070287>:10: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/125\n",
      "781/781 [==============================] - 397s 508ms/step - loss: 4.3213 - accuracy: 0.1255 - val_loss: 3.3741 - val_accuracy: 0.2315 - lr: 0.0010\n",
      "Epoch 2/125\n",
      "781/781 [==============================] - 303s 387ms/step - loss: 3.2777 - accuracy: 0.2375 - val_loss: 2.8736 - val_accuracy: 0.3071 - lr: 0.0010\n",
      "Epoch 3/125\n",
      "781/781 [==============================] - 317s 406ms/step - loss: 2.8447 - accuracy: 0.3092 - val_loss: 2.6834 - val_accuracy: 0.3564 - lr: 0.0010\n",
      "Epoch 4/125\n",
      "781/781 [==============================] - 294s 377ms/step - loss: 2.6211 - accuracy: 0.3563 - val_loss: 2.4265 - val_accuracy: 0.3989 - lr: 0.0010\n",
      "Epoch 5/125\n",
      "781/781 [==============================] - 286s 366ms/step - loss: 2.4906 - accuracy: 0.3862 - val_loss: 2.2624 - val_accuracy: 0.4356 - lr: 0.0010\n",
      "Epoch 6/125\n",
      "781/781 [==============================] - 286s 366ms/step - loss: 2.3946 - accuracy: 0.4116 - val_loss: 2.1618 - val_accuracy: 0.4619 - lr: 0.0010\n",
      "Epoch 7/125\n",
      "781/781 [==============================] - 285s 365ms/step - loss: 2.3317 - accuracy: 0.4231 - val_loss: 2.1047 - val_accuracy: 0.4936 - lr: 0.0010\n",
      "Epoch 8/125\n",
      "781/781 [==============================] - 286s 367ms/step - loss: 2.2780 - accuracy: 0.4408 - val_loss: 2.1591 - val_accuracy: 0.4777 - lr: 0.0010\n",
      "Epoch 9/125\n",
      "781/781 [==============================] - 287s 367ms/step - loss: 2.2246 - accuracy: 0.4539 - val_loss: 2.1309 - val_accuracy: 0.4893 - lr: 0.0010\n",
      "Epoch 10/125\n",
      "781/781 [==============================] - 287s 367ms/step - loss: 2.1873 - accuracy: 0.4638 - val_loss: 2.2476 - val_accuracy: 0.4717 - lr: 0.0010\n",
      "Epoch 11/125\n",
      "781/781 [==============================] - 289s 370ms/step - loss: 2.1571 - accuracy: 0.4714 - val_loss: 2.0733 - val_accuracy: 0.5017 - lr: 0.0010\n",
      "Epoch 12/125\n",
      "781/781 [==============================] - 286s 366ms/step - loss: 2.1381 - accuracy: 0.4757 - val_loss: 1.9534 - val_accuracy: 0.5233 - lr: 0.0010\n",
      "Epoch 13/125\n",
      "781/781 [==============================] - 288s 368ms/step - loss: 2.1138 - accuracy: 0.4836 - val_loss: 2.2178 - val_accuracy: 0.4898 - lr: 0.0010\n",
      "Epoch 14/125\n",
      "781/781 [==============================] - 289s 370ms/step - loss: 2.0983 - accuracy: 0.4878 - val_loss: 2.0528 - val_accuracy: 0.5036 - lr: 0.0010\n",
      "Epoch 15/125\n",
      "781/781 [==============================] - 291s 373ms/step - loss: 2.0772 - accuracy: 0.4961 - val_loss: 2.0845 - val_accuracy: 0.5014 - lr: 0.0010\n",
      "Epoch 16/125\n",
      "781/781 [==============================] - 291s 373ms/step - loss: 2.0564 - accuracy: 0.5006 - val_loss: 2.0260 - val_accuracy: 0.5172 - lr: 0.0010\n",
      "Epoch 17/125\n",
      "781/781 [==============================] - 282s 361ms/step - loss: 2.0491 - accuracy: 0.5036 - val_loss: 2.0294 - val_accuracy: 0.5206 - lr: 0.0010\n",
      "Epoch 18/125\n",
      "781/781 [==============================] - 287s 367ms/step - loss: 2.0406 - accuracy: 0.5113 - val_loss: 1.9861 - val_accuracy: 0.5294 - lr: 0.0010\n",
      "Epoch 19/125\n",
      "781/781 [==============================] - 288s 369ms/step - loss: 2.0174 - accuracy: 0.5151 - val_loss: 1.8993 - val_accuracy: 0.5529 - lr: 0.0010\n",
      "Epoch 20/125\n",
      "781/781 [==============================] - 287s 367ms/step - loss: 2.0012 - accuracy: 0.5161 - val_loss: 2.1039 - val_accuracy: 0.5159 - lr: 0.0010\n",
      "Epoch 21/125\n",
      "781/781 [==============================] - 289s 370ms/step - loss: 1.9937 - accuracy: 0.5207 - val_loss: 1.8815 - val_accuracy: 0.5542 - lr: 0.0010\n",
      "Epoch 22/125\n",
      "781/781 [==============================] - 289s 371ms/step - loss: 1.9836 - accuracy: 0.5258 - val_loss: 1.9785 - val_accuracy: 0.5395 - lr: 0.0010\n",
      "Epoch 23/125\n",
      "781/781 [==============================] - 293s 375ms/step - loss: 1.9748 - accuracy: 0.5248 - val_loss: 1.9301 - val_accuracy: 0.5460 - lr: 0.0010\n",
      "Epoch 24/125\n",
      "781/781 [==============================] - 289s 370ms/step - loss: 1.9678 - accuracy: 0.5295 - val_loss: 1.9282 - val_accuracy: 0.5495 - lr: 0.0010\n",
      "Epoch 25/125\n",
      "781/781 [==============================] - 290s 372ms/step - loss: 1.9661 - accuracy: 0.5301 - val_loss: 1.9853 - val_accuracy: 0.5370 - lr: 0.0010\n",
      "Epoch 26/125\n",
      "781/781 [==============================] - 283s 363ms/step - loss: 1.9512 - accuracy: 0.5357 - val_loss: 1.9524 - val_accuracy: 0.5503 - lr: 0.0010\n",
      "Epoch 27/125\n",
      "781/781 [==============================] - 286s 366ms/step - loss: 1.9454 - accuracy: 0.5354 - val_loss: 2.0217 - val_accuracy: 0.5406 - lr: 0.0010\n",
      "Epoch 28/125\n",
      "781/781 [==============================] - 289s 370ms/step - loss: 1.9457 - accuracy: 0.5341 - val_loss: 1.8936 - val_accuracy: 0.5590 - lr: 0.0010\n",
      "Epoch 29/125\n",
      "781/781 [==============================] - 289s 370ms/step - loss: 1.9367 - accuracy: 0.5391 - val_loss: 2.0173 - val_accuracy: 0.5367 - lr: 0.0010\n",
      "Epoch 30/125\n",
      "781/781 [==============================] - 291s 373ms/step - loss: 1.9240 - accuracy: 0.5434 - val_loss: 2.0011 - val_accuracy: 0.5362 - lr: 0.0010\n",
      "Epoch 31/125\n",
      "781/781 [==============================] - 292s 373ms/step - loss: 1.9190 - accuracy: 0.5462 - val_loss: 2.0629 - val_accuracy: 0.5279 - lr: 0.0010\n",
      "Epoch 32/125\n",
      "781/781 [==============================] - 290s 371ms/step - loss: 1.9112 - accuracy: 0.5466 - val_loss: 2.0506 - val_accuracy: 0.5357 - lr: 0.0010\n",
      "Epoch 33/125\n",
      "781/781 [==============================] - 288s 369ms/step - loss: 1.9075 - accuracy: 0.5488 - val_loss: 1.9834 - val_accuracy: 0.5466 - lr: 0.0010\n",
      "Epoch 34/125\n",
      "781/781 [==============================] - 288s 368ms/step - loss: 1.9083 - accuracy: 0.5481 - val_loss: 1.9324 - val_accuracy: 0.5594 - lr: 0.0010\n",
      "Epoch 35/125\n",
      "781/781 [==============================] - 285s 365ms/step - loss: 1.9041 - accuracy: 0.5484 - val_loss: 1.9416 - val_accuracy: 0.5499 - lr: 0.0010\n",
      "Epoch 36/125\n",
      "781/781 [==============================] - 289s 370ms/step - loss: 1.8996 - accuracy: 0.5519 - val_loss: 1.9503 - val_accuracy: 0.5501 - lr: 0.0010\n",
      "Epoch 37/125\n",
      "781/781 [==============================] - 285s 365ms/step - loss: 1.8871 - accuracy: 0.5542 - val_loss: 1.9452 - val_accuracy: 0.5533 - lr: 0.0010\n",
      "Epoch 38/125\n",
      "781/781 [==============================] - 290s 371ms/step - loss: 1.8951 - accuracy: 0.5543 - val_loss: 1.8930 - val_accuracy: 0.5622 - lr: 0.0010\n",
      "Epoch 39/125\n",
      "781/781 [==============================] - 289s 369ms/step - loss: 1.8911 - accuracy: 0.5557 - val_loss: 1.8708 - val_accuracy: 0.5697 - lr: 0.0010\n",
      "Epoch 40/125\n",
      "781/781 [==============================] - 292s 374ms/step - loss: 1.8820 - accuracy: 0.5557 - val_loss: 1.9387 - val_accuracy: 0.5538 - lr: 0.0010\n",
      "Epoch 41/125\n",
      "781/781 [==============================] - 286s 366ms/step - loss: 1.8761 - accuracy: 0.5588 - val_loss: 1.9648 - val_accuracy: 0.5463 - lr: 0.0010\n",
      "Epoch 42/125\n",
      "781/781 [==============================] - 290s 371ms/step - loss: 1.8850 - accuracy: 0.5535 - val_loss: 2.0371 - val_accuracy: 0.5382 - lr: 0.0010\n",
      "Epoch 43/125\n",
      "781/781 [==============================] - 287s 368ms/step - loss: 1.8726 - accuracy: 0.5572 - val_loss: 1.9225 - val_accuracy: 0.5586 - lr: 0.0010\n",
      "Epoch 44/125\n",
      "781/781 [==============================] - 287s 367ms/step - loss: 1.8677 - accuracy: 0.5609 - val_loss: 1.9150 - val_accuracy: 0.5592 - lr: 0.0010\n",
      "Epoch 45/125\n",
      "781/781 [==============================] - 283s 362ms/step - loss: 1.8695 - accuracy: 0.5619 - val_loss: 1.9114 - val_accuracy: 0.5603 - lr: 0.0010\n",
      "Epoch 46/125\n",
      "781/781 [==============================] - 286s 366ms/step - loss: 1.8615 - accuracy: 0.5633 - val_loss: 1.8684 - val_accuracy: 0.5672 - lr: 0.0010\n",
      "Epoch 47/125\n",
      "781/781 [==============================] - 286s 366ms/step - loss: 1.8595 - accuracy: 0.5624 - val_loss: 1.8690 - val_accuracy: 0.5704 - lr: 0.0010\n",
      "Epoch 48/125\n",
      "781/781 [==============================] - 292s 374ms/step - loss: 1.8555 - accuracy: 0.5628 - val_loss: 1.8522 - val_accuracy: 0.5745 - lr: 0.0010\n",
      "Epoch 49/125\n",
      "781/781 [==============================] - 289s 370ms/step - loss: 1.8563 - accuracy: 0.5635 - val_loss: 1.9030 - val_accuracy: 0.5706 - lr: 0.0010\n",
      "Epoch 50/125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "781/781 [==============================] - 283s 362ms/step - loss: 1.8515 - accuracy: 0.5644 - val_loss: 1.8488 - val_accuracy: 0.5766 - lr: 0.0010\n",
      "Epoch 51/125\n",
      "781/781 [==============================] - 282s 361ms/step - loss: 1.8482 - accuracy: 0.5656 - val_loss: 1.9631 - val_accuracy: 0.5544 - lr: 0.0010\n",
      "Epoch 52/125\n",
      "781/781 [==============================] - 285s 365ms/step - loss: 1.8487 - accuracy: 0.5649 - val_loss: 1.8145 - val_accuracy: 0.5798 - lr: 0.0010\n",
      "Epoch 53/125\n",
      "781/781 [==============================] - 284s 364ms/step - loss: 1.8408 - accuracy: 0.5662 - val_loss: 1.8615 - val_accuracy: 0.5768 - lr: 0.0010\n",
      "Epoch 54/125\n",
      "781/781 [==============================] - 279s 357ms/step - loss: 1.8434 - accuracy: 0.5693 - val_loss: 2.0210 - val_accuracy: 0.5431 - lr: 0.0010\n",
      "Epoch 55/125\n",
      "781/781 [==============================] - 281s 360ms/step - loss: 1.8346 - accuracy: 0.5686 - val_loss: 1.9345 - val_accuracy: 0.5584 - lr: 0.0010\n",
      "Epoch 56/125\n",
      "781/781 [==============================] - 280s 358ms/step - loss: 1.8501 - accuracy: 0.5650 - val_loss: 1.8727 - val_accuracy: 0.5730 - lr: 0.0010\n",
      "Epoch 57/125\n",
      "781/781 [==============================] - 281s 360ms/step - loss: 1.8325 - accuracy: 0.5709 - val_loss: 2.0127 - val_accuracy: 0.5493 - lr: 0.0010\n",
      "Epoch 58/125\n",
      "781/781 [==============================] - 282s 361ms/step - loss: 1.8362 - accuracy: 0.5701 - val_loss: 1.9904 - val_accuracy: 0.5531 - lr: 0.0010\n",
      "Epoch 59/125\n",
      "781/781 [==============================] - 284s 364ms/step - loss: 1.8356 - accuracy: 0.5708 - val_loss: 1.9377 - val_accuracy: 0.5652 - lr: 0.0010\n",
      "Epoch 60/125\n",
      "781/781 [==============================] - 283s 363ms/step - loss: 1.8276 - accuracy: 0.5736 - val_loss: 1.8181 - val_accuracy: 0.5813 - lr: 0.0010\n",
      "Epoch 61/125\n",
      "781/781 [==============================] - 285s 364ms/step - loss: 1.8269 - accuracy: 0.5713 - val_loss: 1.8912 - val_accuracy: 0.5702 - lr: 0.0010\n",
      "Epoch 62/125\n",
      "781/781 [==============================] - 282s 361ms/step - loss: 1.8235 - accuracy: 0.5752 - val_loss: 1.9161 - val_accuracy: 0.5641 - lr: 0.0010\n",
      "Epoch 63/125\n",
      "781/781 [==============================] - 278s 356ms/step - loss: 1.8227 - accuracy: 0.5729 - val_loss: 1.9793 - val_accuracy: 0.5563 - lr: 0.0010\n",
      "Epoch 64/125\n",
      "781/781 [==============================] - 281s 359ms/step - loss: 1.8327 - accuracy: 0.5705 - val_loss: 1.8752 - val_accuracy: 0.5768 - lr: 0.0010\n",
      "Epoch 65/125\n",
      "781/781 [==============================] - 283s 362ms/step - loss: 1.8167 - accuracy: 0.5771 - val_loss: 1.8458 - val_accuracy: 0.5818 - lr: 0.0010\n",
      "Epoch 66/125\n",
      "781/781 [==============================] - 284s 363ms/step - loss: 1.8301 - accuracy: 0.5749 - val_loss: 1.8960 - val_accuracy: 0.5725 - lr: 0.0010\n",
      "Epoch 67/125\n",
      "781/781 [==============================] - 285s 365ms/step - loss: 1.8105 - accuracy: 0.5765 - val_loss: 1.8136 - val_accuracy: 0.5840 - lr: 0.0010\n",
      "Epoch 68/125\n",
      "781/781 [==============================] - 283s 363ms/step - loss: 1.8178 - accuracy: 0.5743 - val_loss: 1.8743 - val_accuracy: 0.5719 - lr: 0.0010\n",
      "Epoch 69/125\n",
      "781/781 [==============================] - 286s 366ms/step - loss: 1.8105 - accuracy: 0.5780 - val_loss: 1.8184 - val_accuracy: 0.5871 - lr: 0.0010\n",
      "Epoch 70/125\n",
      "781/781 [==============================] - 285s 365ms/step - loss: 1.8075 - accuracy: 0.5781 - val_loss: 1.8908 - val_accuracy: 0.5713 - lr: 0.0010\n",
      "Epoch 71/125\n",
      "781/781 [==============================] - 285s 365ms/step - loss: 1.8066 - accuracy: 0.5781 - val_loss: 1.8780 - val_accuracy: 0.5722 - lr: 0.0010\n",
      "Epoch 72/125\n",
      "781/781 [==============================] - 282s 361ms/step - loss: 1.8047 - accuracy: 0.5774 - val_loss: 1.8083 - val_accuracy: 0.5930 - lr: 0.0010\n",
      "Epoch 73/125\n",
      "781/781 [==============================] - 281s 360ms/step - loss: 1.8138 - accuracy: 0.5761 - val_loss: 1.8521 - val_accuracy: 0.5788 - lr: 0.0010\n",
      "Epoch 74/125\n",
      "781/781 [==============================] - 279s 357ms/step - loss: 1.8007 - accuracy: 0.5775 - val_loss: 1.8559 - val_accuracy: 0.5812 - lr: 0.0010\n",
      "Epoch 75/125\n",
      "781/781 [==============================] - 281s 360ms/step - loss: 1.7997 - accuracy: 0.5804 - val_loss: 1.9564 - val_accuracy: 0.5596 - lr: 0.0010\n",
      "Epoch 76/125\n",
      "781/781 [==============================] - 283s 362ms/step - loss: 1.7995 - accuracy: 0.5815 - val_loss: 1.9515 - val_accuracy: 0.5621 - lr: 0.0010\n",
      "Epoch 77/125\n",
      "781/781 [==============================] - 284s 363ms/step - loss: 1.6956 - accuracy: 0.6050 - val_loss: 1.8759 - val_accuracy: 0.5783 - lr: 5.0000e-04\n",
      "Epoch 78/125\n",
      "781/781 [==============================] - 281s 360ms/step - loss: 1.6559 - accuracy: 0.6118 - val_loss: 1.7527 - val_accuracy: 0.6029 - lr: 5.0000e-04\n",
      "Epoch 79/125\n",
      "781/781 [==============================] - 285s 365ms/step - loss: 1.6493 - accuracy: 0.6136 - val_loss: 1.7746 - val_accuracy: 0.5962 - lr: 5.0000e-04\n",
      "Epoch 80/125\n",
      "781/781 [==============================] - 286s 367ms/step - loss: 1.6345 - accuracy: 0.6150 - val_loss: 1.7536 - val_accuracy: 0.6032 - lr: 5.0000e-04\n",
      "Epoch 81/125\n",
      "781/781 [==============================] - 282s 361ms/step - loss: 1.6255 - accuracy: 0.6174 - val_loss: 1.7233 - val_accuracy: 0.6122 - lr: 5.0000e-04\n",
      "Epoch 82/125\n",
      "781/781 [==============================] - 275s 352ms/step - loss: 1.6126 - accuracy: 0.6224 - val_loss: 1.7501 - val_accuracy: 0.5986 - lr: 5.0000e-04\n",
      "Epoch 83/125\n",
      "781/781 [==============================] - 281s 359ms/step - loss: 1.6090 - accuracy: 0.6201 - val_loss: 1.7830 - val_accuracy: 0.5919 - lr: 5.0000e-04\n",
      "Epoch 84/125\n",
      "781/781 [==============================] - 279s 358ms/step - loss: 1.6056 - accuracy: 0.6215 - val_loss: 1.7461 - val_accuracy: 0.6000 - lr: 5.0000e-04\n",
      "Epoch 85/125\n",
      "781/781 [==============================] - 283s 362ms/step - loss: 1.5961 - accuracy: 0.6200 - val_loss: 1.7779 - val_accuracy: 0.5965 - lr: 5.0000e-04\n",
      "Epoch 86/125\n",
      "781/781 [==============================] - 279s 357ms/step - loss: 1.5973 - accuracy: 0.6212 - val_loss: 1.7753 - val_accuracy: 0.5927 - lr: 5.0000e-04\n",
      "Epoch 87/125\n",
      "781/781 [==============================] - 305s 391ms/step - loss: 1.5801 - accuracy: 0.6245 - val_loss: 1.7260 - val_accuracy: 0.6080 - lr: 5.0000e-04\n",
      "Epoch 88/125\n",
      "781/781 [==============================] - 286s 367ms/step - loss: 1.5865 - accuracy: 0.6221 - val_loss: 1.7916 - val_accuracy: 0.5924 - lr: 5.0000e-04\n",
      "Epoch 89/125\n",
      "781/781 [==============================] - 284s 364ms/step - loss: 1.5737 - accuracy: 0.6262 - val_loss: 1.7411 - val_accuracy: 0.6011 - lr: 5.0000e-04\n",
      "Epoch 90/125\n",
      "781/781 [==============================] - 282s 362ms/step - loss: 1.5762 - accuracy: 0.6245 - val_loss: 1.7039 - val_accuracy: 0.6063 - lr: 5.0000e-04\n",
      "Epoch 91/125\n",
      "781/781 [==============================] - 278s 356ms/step - loss: 1.5780 - accuracy: 0.6237 - val_loss: 1.6832 - val_accuracy: 0.6114 - lr: 5.0000e-04\n",
      "Epoch 92/125\n",
      "781/781 [==============================] - 281s 360ms/step - loss: 1.5685 - accuracy: 0.6272 - val_loss: 1.6820 - val_accuracy: 0.6103 - lr: 5.0000e-04\n",
      "Epoch 93/125\n",
      "781/781 [==============================] - 299s 382ms/step - loss: 1.5714 - accuracy: 0.6255 - val_loss: 1.6959 - val_accuracy: 0.6126 - lr: 5.0000e-04\n",
      "Epoch 94/125\n",
      "781/781 [==============================] - 321s 412ms/step - loss: 1.5691 - accuracy: 0.6257 - val_loss: 1.7030 - val_accuracy: 0.6038 - lr: 5.0000e-04\n",
      "Epoch 95/125\n",
      "781/781 [==============================] - 309s 396ms/step - loss: 1.5656 - accuracy: 0.6262 - val_loss: 1.7391 - val_accuracy: 0.5952 - lr: 5.0000e-04\n",
      "Epoch 96/125\n",
      "781/781 [==============================] - 289s 370ms/step - loss: 1.5656 - accuracy: 0.6242 - val_loss: 1.7316 - val_accuracy: 0.6055 - lr: 5.0000e-04\n",
      "Epoch 97/125\n",
      "781/781 [==============================] - 288s 369ms/step - loss: 1.5627 - accuracy: 0.6263 - val_loss: 1.6813 - val_accuracy: 0.6128 - lr: 5.0000e-04\n",
      "Epoch 98/125\n",
      "781/781 [==============================] - 289s 370ms/step - loss: 1.5467 - accuracy: 0.6288 - val_loss: 1.7278 - val_accuracy: 0.6002 - lr: 5.0000e-04\n",
      "Epoch 99/125\n",
      "781/781 [==============================] - 293s 375ms/step - loss: 1.5633 - accuracy: 0.6255 - val_loss: 1.6630 - val_accuracy: 0.6122 - lr: 5.0000e-04\n",
      "Epoch 100/125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "781/781 [==============================] - 316s 405ms/step - loss: 1.5605 - accuracy: 0.6241 - val_loss: 1.7265 - val_accuracy: 0.6032 - lr: 5.0000e-04\n",
      "Epoch 101/125\n",
      "781/781 [==============================] - 283s 363ms/step - loss: 1.5487 - accuracy: 0.6290 - val_loss: 1.7179 - val_accuracy: 0.5986 - lr: 5.0000e-04\n",
      "Epoch 102/125\n",
      "781/781 [==============================] - 295s 377ms/step - loss: 1.5014 - accuracy: 0.6370 - val_loss: 1.6701 - val_accuracy: 0.6100 - lr: 3.0000e-04\n",
      "Epoch 103/125\n",
      "781/781 [==============================] - 321s 410ms/step - loss: 1.4884 - accuracy: 0.6414 - val_loss: 1.6930 - val_accuracy: 0.6080 - lr: 3.0000e-04\n",
      "Epoch 104/125\n",
      "781/781 [==============================] - 298s 381ms/step - loss: 1.4670 - accuracy: 0.6475 - val_loss: 1.6438 - val_accuracy: 0.6192 - lr: 3.0000e-04\n",
      "Epoch 105/125\n",
      "781/781 [==============================] - 288s 368ms/step - loss: 1.4772 - accuracy: 0.6427 - val_loss: 1.6561 - val_accuracy: 0.6166 - lr: 3.0000e-04\n",
      "Epoch 106/125\n",
      "781/781 [==============================] - 286s 367ms/step - loss: 1.4680 - accuracy: 0.6489 - val_loss: 1.6545 - val_accuracy: 0.6153 - lr: 3.0000e-04\n",
      "Epoch 107/125\n",
      "781/781 [==============================] - 288s 369ms/step - loss: 1.4588 - accuracy: 0.6485 - val_loss: 1.6806 - val_accuracy: 0.6106 - lr: 3.0000e-04\n",
      "Epoch 108/125\n",
      "781/781 [==============================] - 285s 365ms/step - loss: 1.4590 - accuracy: 0.6490 - val_loss: 1.6524 - val_accuracy: 0.6130 - lr: 3.0000e-04\n",
      "Epoch 109/125\n",
      "781/781 [==============================] - 296s 379ms/step - loss: 1.4577 - accuracy: 0.6481 - val_loss: 1.6510 - val_accuracy: 0.6175 - lr: 3.0000e-04\n",
      "Epoch 110/125\n",
      "781/781 [==============================] - 293s 375ms/step - loss: 1.4412 - accuracy: 0.6509 - val_loss: 1.6529 - val_accuracy: 0.6136 - lr: 3.0000e-04\n",
      "Epoch 111/125\n",
      "781/781 [==============================] - 289s 370ms/step - loss: 1.4477 - accuracy: 0.6496 - val_loss: 1.6635 - val_accuracy: 0.6154 - lr: 3.0000e-04\n",
      "Epoch 112/125\n",
      "781/781 [==============================] - 320s 410ms/step - loss: 1.4589 - accuracy: 0.6458 - val_loss: 1.6691 - val_accuracy: 0.6112 - lr: 3.0000e-04\n",
      "Epoch 113/125\n",
      "781/781 [==============================] - 292s 374ms/step - loss: 1.4432 - accuracy: 0.6508 - val_loss: 1.6394 - val_accuracy: 0.6192 - lr: 3.0000e-04\n",
      "Epoch 114/125\n",
      "781/781 [==============================] - 291s 372ms/step - loss: 1.4456 - accuracy: 0.6482 - val_loss: 1.6832 - val_accuracy: 0.6095 - lr: 3.0000e-04\n",
      "Epoch 115/125\n",
      "781/781 [==============================] - 286s 367ms/step - loss: 1.4287 - accuracy: 0.6528 - val_loss: 1.6531 - val_accuracy: 0.6153 - lr: 3.0000e-04\n",
      "Epoch 116/125\n",
      "781/781 [==============================] - 290s 371ms/step - loss: 1.4422 - accuracy: 0.6502 - val_loss: 1.6513 - val_accuracy: 0.6135 - lr: 3.0000e-04\n",
      "Epoch 117/125\n",
      "781/781 [==============================] - 289s 370ms/step - loss: 1.4326 - accuracy: 0.6517 - val_loss: 1.6270 - val_accuracy: 0.6203 - lr: 3.0000e-04\n",
      "Epoch 118/125\n",
      "781/781 [==============================] - 289s 371ms/step - loss: 1.4349 - accuracy: 0.6511 - val_loss: 1.6566 - val_accuracy: 0.6169 - lr: 3.0000e-04\n",
      "Epoch 119/125\n",
      "781/781 [==============================] - 287s 368ms/step - loss: 1.4253 - accuracy: 0.6521 - val_loss: 1.6003 - val_accuracy: 0.6267 - lr: 3.0000e-04\n",
      "Epoch 120/125\n",
      "781/781 [==============================] - 286s 366ms/step - loss: 1.4309 - accuracy: 0.6510 - val_loss: 1.6426 - val_accuracy: 0.6151 - lr: 3.0000e-04\n",
      "Epoch 121/125\n",
      "781/781 [==============================] - 288s 369ms/step - loss: 1.4336 - accuracy: 0.6506 - val_loss: 1.6397 - val_accuracy: 0.6175 - lr: 3.0000e-04\n",
      "Epoch 122/125\n",
      "781/781 [==============================] - 290s 371ms/step - loss: 1.4284 - accuracy: 0.6510 - val_loss: 1.6715 - val_accuracy: 0.6089 - lr: 3.0000e-04\n",
      "Epoch 123/125\n",
      "781/781 [==============================] - 299s 383ms/step - loss: 1.4292 - accuracy: 0.6510 - val_loss: 1.6500 - val_accuracy: 0.6145 - lr: 3.0000e-04\n",
      "Epoch 124/125\n",
      "781/781 [==============================] - 303s 388ms/step - loss: 1.4227 - accuracy: 0.6541 - val_loss: 1.6253 - val_accuracy: 0.6198 - lr: 3.0000e-04\n",
      "Epoch 125/125\n",
      "781/781 [==============================] - 294s 377ms/step - loss: 1.4237 - accuracy: 0.6542 - val_loss: 1.6443 - val_accuracy: 0.6168 - lr: 3.0000e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x63ba5afd0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras import optimizers\n",
    "\n",
    "#training\n",
    "batch_size = 64\n",
    " \n",
    "opt_rms = optimizers.RMSprop(lr=0.001,decay=1e-6)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt_rms, metrics=['accuracy'])\n",
    "model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\\\n",
    "                    steps_per_epoch=x_train.shape[0] // batch_size,epochs=125,\\\n",
    "                    verbose=1,validation_data=(x_test,y_test),callbacks=[LearningRateScheduler(lr_schedule)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 16s 204ms/step - loss: 1.6443 - accuracy: 0.6168\n",
      "\n",
      "Test result: 61.680 loss: 1.644\n"
     ]
    }
   ],
   "source": [
    "#save to disk\n",
    "model_json = model.to_json()\n",
    "with open('model_100.json', 'w') as json_file:\n",
    "    json_file.write(model_json)\n",
    "model.save_weights('model_100.h5') \n",
    " \n",
    "#testing\n",
    "scores = model.evaluate(x_test, y_test, batch_size=128, verbose=1)\n",
    "print('\\nTest result: %.3f loss: %.3f' % (scores[1]*100,scores[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
